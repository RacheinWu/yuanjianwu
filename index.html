<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="illusions/maomaotou.png">
    <title>Yuanjian Wu | Academic Homepage</title>
    <style>
        /* Base Reset */
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: "Helvetica Neue", Arial, sans-serif;
            /*background-color: #f5f5e0;*/
            background-color: #fffff5;
            color: #333;
            line-height: 1.6;
            min-width: 1070px;
        }

        a {
            color: #004d40;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        /* Main layout */
        .main-part {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 40px 20px 40px 40px;
        }

        .header {
            display: flex;
            align-items: center;
            max-width: 900px;
            width: 100%;
            margin-bottom: 60px;
        }

        .header .left-box {
            flex: 1;
            max-width: 650px;
        }

        .header .right-box {
            width: 150px;
            height: 150px;
            margin-left: 40px;
        }

        .header img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            /*border-radius: 8px;*/
            /*border: 2px solid #004d40;*/
        }

        .name {
            display: flex;
            align-items: baseline;
            font-size: 33px;
            color: #004d40;
        }

        .name .zhongwen {
            margin-left: 20px;
            font-size: 24px;
            color: #004d40;
        }

        .description {
            margin-top: 16px;
        }

        .description p {
            margin-top: 12px;
        }

        .highlight {
            color: #004d40;
            font-weight: bold;
        }

        .note {
            margin-top: 16px;
            color: red;
        }

        /* Section titles */
        section {
            /*width: 100%;*/
            /*max-width: 1000px;*/
            margin-bottom: 60px;
        }

        section h2 {
            font-size: 24px;
            color: #004d40;
            border-bottom: 2px solid #004d40;
            display: inline-block;
            margin-bottom: 24px;
            padding-bottom: 4px;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
            gap: 20px;
        }

        .grid img {
            width: 100%;
            height: auto;
            border-radius: 4px;
            border: 1px solid #ccc;
        }

        .publication {
            text-align: center;
        }

        .publication h3 {
            margin-top: 8px;
            font-size: 16px;
        }
    </style>
</head>
<body>
<div class="main-part">
    <!-- Header: Name, Info, Photo -->
    <div class="header">
        <div class="left-box">
            <div class="name">
                <div class="yingwen">Yuanjian Wu</div>
                <div class="zhongwen">吴远健</div>
            </div>
            <div class="description">
                <p>Hi, I am Yuanjian. I am currently a Master Student at Sun Yat-sen University (SYSU).</p>
                <p>My research interests include <span class="highlight">Computer Vision</span> and <span
                        class="highlight">MLLMs</span>, specifically AIGC for 2D/3D vision, Robotics, etc.</p>
                <p><a href="#">GitHub</a> / Email / Zhihu / <a
                        href="https://space.bilibili.com/12750464" target="_blank">Bilibili</a> / <a href="#">Google
                    Scholar</a></p>
                <p class="note">★ 2025/4/6 Now, I am studying VLM & VLA ......</p>
                <p class="note">★ 2025/4/29 🎉 Conducted research as a Visiting Student at the
                    <a href="https://zhuanghp.github.io/">MIAA Lab</a>,
                    South China University of Technology (SCUT).</p>
            </div>
        </div>
        <div class="right-box">
<!--            <img src="illusions/tx.jpg" alt="Yuanjian Wu">-->
        </div>
    </div>


    <div style="display: flex; width: 970px;justify-content: flex-start;
}">
        <div class="left-box-quwei">
            <iframe src="typing-box.html" width="520" height="300" style="border:none;"></iframe>
        </div>

        <div style="width: 300px;height: 110px;padding-top: 8px">
            <script type='text/javascript' id='clustrmaps'
                    src='//cdn.clustrmaps.com/map_v2.js?cl=9a9a9a&w=400&t=tt&d=PCxKV0X3F1oDf26zC7ringTxoxyzSYHgAehFzqPtcNg&co=fffff5&cmo=057434&cmn=15d20a&ct=028d13'></script>
        </div>


    </div>

    <div style="color: #004d40">❀ ❀ ❀ ❀ ❀ ❀❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀❀ ❀
        ❀ ❀ ❀ ❀ ❀ ❀ ❀
    </div>

    <section>
        <h2>Recent Learning & Note</h2>
        <div style="margin: 0 0 15px 0">
            <!--            <iframe src="recent_learning.html" width="990px" height=""></iframe>-->

            <div style="width: 990px;background-color: #ffffff;border: 1px solid #e1e4e8; padding: 10px 20px 10px 20px ">
                <div>
                    <h3><span>#1</span>
                        <span style="color: rgb(1,120,55)">Why can LLMs inherently achieve few-shot learning?</span>
<!--                        <span style="color: rgb(236,101,0)">[Notion] [Zhihu] [Bilibili]</span>-->
                        <span style="color: rgb(236,101,0)">[Notion]</span>
                    </h3>
                </div>
                <div>
                   LLMs are built on the transformer architecture, which enables them to grasp the requirements of specific tasks and generate appropriate responses under prompts, such as in few-shot learning. This is remarkable because, with just a few examples, the network can comprehend, analyze, and address a wide range of new problems. For example, given a set of questions with various textual combinations and their corresponding answers, the model can understand the task and generate responses to new questions within that task. But why does this happen? The primary reason lies in the unique design of transformers, which brings about these positive effects. In this note, we will explore this from four key aspects of transformers: 1. Approximate meta-learning design (function selection strategy) 2. Attention-forward strategy without parameter updates 3. First-order gradient descent 4. Massive dataset stacking training with high resource demands. By examining these four perspectives, we can understand why LLMs can achieve task understanding in few-shot settings.
                </div>
                <div>
                    <h4>Subject: <span style="color: rgb(236,101,0)">LLMs</span>, <span style="color: rgb(236,101,0)">Few-shot Learning</span>
                    </h4>
                </div>
                <div>
                    <h4>Updated-time: <span style="font-weight: normal">2025-05-06</span></h4>
                </div>
            </div>
        </div>


        <div style="margin: 15px 0 15px 0">
            <!--            <iframe src="recent_learning.html" width="990px" height=""></iframe>-->

            <div style="width: 990px;background-color: #ffffff;border: 1px solid #e1e4e8; padding: 10px 20px 10px 20px ">
                <div>
                    <h3><span>#2</span>
                        <span style="color: rgb(1,120,55)">Understanding and Development of Continual Learning in LLMs</span>
<!--                        <span style="color: rgb(236,101,0)">[Notion] [Zhihu] [Bilibili]</span>-->
                        <span style="color: rgb(236,101,0)">[Notion] </span>
                    </h3>
                </div>
                <div>
LLMs rely heavily on large-scale training datasets and immense GPU computing power, making the training process highly expensive. In traditional model fine-tuning, retraining is often necessary, which can hinder further progress due to the high costs involved. Moreover, even after pre-training, models require fine-tuning to adapt to new tasks. However, fine-tuning does not always lead to effective adaptation; instead, it can cause 'memory forgetting' of previous tasks. Specifically, as new tasks are learned, adjustments made to the network parameters based on the new training data, without the positive constraints from the old training data, can result in a decline in performance on the old tasks. In recent years, continual learning has emerged as a key solution to this challenge. In this note, I will explore the integration of continual learning with VLMs, highlighting cutting-edge research on continual learning for multimodal large models (VLMs) from the perspective of continual learning.                </div>
                <div>
                    <h4>Subject: <span style="color: rgb(236,101,0)">LLMs</span>, <span style="color: rgb(236,101,0)">Continual Learning</span>
                    </h4>
                </div>
                <div>
                    <h4>Updated-time: <span style="font-weight: normal">2025-05-06</span></h4>
                </div>
            </div>
        </div>

    </section>

    <!-- Recent Learning Section -->
    <section id="learning">
        <h2>Recent Research</h2>
        <div>
            <iframe src="kuang.html" width="1000px" height="442px" style="border:1px solid #e1e4e8;"></iframe>
        </div>
    </section>

    <!--    bottom-banner-->
    <div style="color: #004d40;margin-bottom: 20px">❀ ❀❀ ❀ ❀ ❀ ❀ ❀ ❀❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀
        ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀ ❀
        ❀❀ ❀
        ❀ ❀ ❀ ❀ ❀ ❀ ❀
    </div>

    <section id="honor">
        <h2>Honor</h2>
        <div style="display: flex;width: 1000px;    flex-direction: column;">
            <url>

                <li>China Collegiate Algorithm Design & Programming Challenge Contest <span
                        style="color: goldenrod; font-weight: bold">🥈National Silver Award</span></li>
                <li>The 9" China International College Students’ "internet +’ Innovation and Entrepreneurship
                    Competition <span style="color: lightslategray; font-weight: bold">🥉 Province Bronze Award</span>
                </li>
                <li>Awarded Top <span style="color: rgba(179,5,5,0.87); font-weight: bold">3 (3/150) </span>in
                    Graduation Thesis within the Computer Science Department.
                </li>
                <li><span style="color: rgba(179,5,5,0.87); font-weight: bold">Honor Member</span> of ITA3M Lab from 1st
                    to 3rd year of Master’s program.
                </li>
                <li>Completion of a key national software project titled 'Blue Grain Warehouse'.</li>
            </url>

        </div>

    </section>
    <!--    <div style="width: 300px;height: 220px">-->

    <!--        <img style="height: 100%;width: 100%"-->

    <!--                src="//clustrmaps.com/map_v2.png?cl=a2a2a2&w=900&t=tt&d=PCxKV0X3F1oDf26zC7ringTxoxyzSYHgAehFzqPtcNg&co=fffff5&ct=056f25" />-->
    <!--    </div>-->

    <!--    -->
    <!--    <script type='text/javascript' id='clustrmaps'-->
    <!--            src='//cdn.clustrmaps.com/map_v2.js?cl=a2a2a2&w=900&t=tt&d=PCxKV0X3F1oDf26zC7ringTxoxyzSYHgAehFzqPtcNg&co=fffff5&ct=056f25'></script>-->
    <div style="display: flex; padding-top: 10px;width: 1000px;justify-content: space-between;border-top: 1px solid rgb(0,88,38)">
        <div style="display: flex;">
            <div style="display: flex;flex-direction: column;justify-content: space-evenly;">
                <div>Template author: Rachein Wu</div>
                <div>Host: Rachein Wu</div>
            </div>

            <div><img src="illusions/xiaoxun.png" style="height: 90px;margin-left: 20px"></div>
            <div class="right-box-quwei" style="height: 90px;width: 90px;margin-left: 20px">
                <img src="illusions/xiaohui.png" style="height: 100%;width: 100%">
            </div>
        </div>
        <div>
            <img src="illusions/tree.png" style="width: 80px;height: 80px">

        </div>
    </div>


</div>
</body>
</html>
